u <- as.integer(u_str)
items_u <- ratings$items[[u_str]]
r_u     <- ratings$ratings[[u_str]]
if (length(items_u) == 0) next
# Implicit feedback sum
sqrt_n <- 1 / sqrt(length(items_u))
sum_y  <- colSums(yj[items_u, , drop = FALSE]) * sqrt_n
p_plus <- pu[u, ] + sum_y
# Predictions and error
q_sub   <- qi[items_u, , drop = FALSE]
preds_u <- mu + bu[u] + bi[items_u] + q_sub %*% p_plus
errs    <- as.vector(r_u - preds_u)
# Bias updates
bu[u]       <- bu[u] + lr * (mean(errs) - lambda * bu[u])
bi[items_u] <- bi[items_u] + lr * (errs - lambda * bi[items_u])
# Latent updates
pu[u, ]      <- pu[u, ] + lr * (t(q_sub) %*% errs - lambda * pu[u, ])
pu_term      <- matrix(p_plus, nrow = length(errs), ncol = k, byrow = TRUE)
qi[items_u,] <- qi[items_u,] + lr * (errs * pu_term - lambda * qi[items_u,])
yj[items_u,] <- yj[items_u,] + lr * (errs * pu_term * sqrt_n - lambda * yj[items_u,])
}
lr <- lr * 0.9
# record epoch time
t1 <- proc.time()[3]
epoch_times[epoch] <- t1 - t0
}
return(list(mu = mu, bu = bu, bi = bi, pu = pu, qi = qi, yj = yj,
epoch_times = epoch_times))
}
# Predict function for SVD++
predict_SVDpp <- function(model, test_df) {
mu <- model$mu; bu <- model$bu; bi <- model$bi
pu <- model$pu; qi <- model$qi; yj <- model$yj
ratings_test <- build_rating_lists(test_df)
preds <- numeric(nrow(test_df))
for (n in seq_len(nrow(test_df))) {
u <- test_df$user[n]; i <- test_df$item[n]
items_u <- ratings_test$items[[as.character(u)]]
if (length(items_u) == 0) {
sum_y <- rep(0, ncol(yj))
} else {
sqrt_n <- 1 / sqrt(length(items_u))
sum_y  <- colSums(yj[items_u, , drop = FALSE]) * sqrt_n
}
preds[n] <- as.numeric(mu + bu[u] + bi[i] + (pu[u, ] + sum_y) %*% qi[i, ])
}
return(preds)
}
train_CBSVDpp <- function(train_df, n_users, n_items,
n_clusters = 10,
k = 50, lr = 0.01, lambda = 0.02,
n_epochs = 20, alpha = 0.2) {
# Train base SVD++
base <- train_SVDpp(train_df, n_users, n_items, k, lr, lambda, n_epochs)
epoch_times <- base$epoch_times
# Start timer for clustering
t0_cluster <- proc.time()[3]
# Cluster on base latents
uc <- kmeans(base$pu, centers = n_clusters, iter.max = 50)$cluster
ic <- kmeans(base$qi, centers = n_clusters, iter.max = 50)$cluster
# Compute cluster-level latent means
pu_c <- t(sapply(split(seq_len(nrow(base$pu)), uc), function(idx) colMeans(base$pu[idx, , drop = FALSE])))
qi_c <- t(sapply(split(seq_len(nrow(base$qi)), ic), function(idx) colMeans(base$qi[idx, , drop = FALSE])))
yj_c <- t(sapply(split(seq_len(nrow(base$yj)), ic), function(idx) colMeans(base$yj[idx, , drop = FALSE])))
# Compute cluster-pair rating averages
df <- train_df
df$uc <- uc[df$user]
df$ic <- ic[df$item]
Rstar <- with(df, tapply(rating, list(uc, ic), mean))
Rstar[is.na(Rstar)] <- base$mu
# Get time spent on clustering
cluster_time <- proc.time()[3] - t0_cluster
return(list(mu = base$mu,
bu = base$bu, bi = base$bi,
pu = base$pu, qi = base$qi, yj = base$yj,
pu_c = pu_c, qi_c = qi_c, yj_c = yj_c,
uc = uc, ic = ic,
alpha = alpha,
Rstar = Rstar,
epoch_times = epoch_times,
cluster_time = cluster_time))
}
# Predict function for CB-SVD++
predict_CBSVDpp <- function(model, test_df) {
mu <- model$mu; bu <- model$bu; bi <- model$bi
pu <- model$pu; qi <- model$qi; yj <- model$yj
pu_c <- model$pu_c; qi_c <- model$qi_c; yj_c <- model$yj_c
uc <- model$uc; ic <- model$ic; alpha <- model$alpha
Rstar <- model$Rstar
ratings_test <- build_rating_lists(test_df)
preds <- numeric(nrow(test_df))
for (n in seq_len(nrow(test_df))) {
u <- test_df$user[n]; i <- test_df$item[n]
items_u <- ratings_test$items[[as.character(u)]]
if (length(items_u) == 0) {
sum_y <- rep(0, ncol(yj))
} else {
sqrt_n <- 1 / sqrt(length(items_u))
sum_y_base  <- colSums(yj[items_u, , drop = FALSE]) * sqrt_n
sum_y_clust <- colSums(yj_c[ic[items_u], , drop = FALSE]) * sqrt_n
sum_y       <- (1 - alpha) * sum_y_base + alpha * sum_y_clust
}
q_mix <- (1 - alpha) * qi[i, ] + alpha * qi_c[ic[i], ]
p_mix <- (1 - alpha) * pu[u, ] + alpha * pu_c[uc[u], ]
preds[n] <- as.numeric(mu + bu[u] + bi[i] + q_mix %*% (p_mix + sum_y) + alpha * (Rstar[uc[u], ic[i]] - mu))
}
return(preds)
}
train_ASVDpp <- function(train_df, n_users, n_items,
k=50, lr=0.01, lambda=0.02,
n_epochs=20) {
# Get SVD++ base (biases and implicit factors)
base <- train_SVDpp(train_df, n_users, n_items, k, lr, lambda, n_epochs)
epoch_times <- base$epoch_times
# Start ASVD timer
t0_build <- proc.time()[3]
mu   <- base$mu; bu <- base$bu; bi <- base$bi
pu   <- base$pu; qi <- base$qi; yj <- base$yj
# Build feedback lists
ratings <- build_rating_lists(train_df)
imp_items <- ratings$items
# Build explicit+implicit user embeddings
user_emb <- matrix(0, nrow=n_users, ncol=k)
for (u_str in names(imp_items)) {
u <- as.integer(u_str)
items_u <- imp_items[[u_str]]
r_u     <- ratings$ratings[[u_str]]
if (length(items_u)==0) next
# explicit centered
centered <- r_u - (mu + bu[u] + bi[items_u])
# implicit sum
sqrt_imp <- 1 / sqrt(length(items_u))
sum_y    <- colSums(yj[items_u, , drop=FALSE]) * sqrt_imp
# combine explicit and implicit
user_emb[u, ] <- colSums(qi[items_u, , drop=FALSE] * centered) / (length(items_u) + lambda)
# Get time spent on clustering
t1_build <- proc.time()[3]
build_time <- t1_build - t0_build
}
return(list(mu=mu, bu=bu, bi=bi,
pu=pu, qi=qi, yj=yj,
user_emb=user_emb,
imp_items=imp_items,
epoch_times = epoch_times,
build_time  = build_time))
}
predict_ASVDpp <- function(model, test_df) {
mu <- model$mu; bu <- model$bu; bi <- model$bi
pu <- model$pu; qi <- model$qi; yj <- model$yj
user_emb  <- model$user_emb; imp_items <- model$imp_items
preds <- numeric(nrow(test_df))
for (n in seq_len(nrow(test_df))) {
u <- test_df$user[n]; i <- test_df$item[n]
# implicit
items_imp <- imp_items[[as.character(u)]]
if (length(items_imp)==0) {
sum_y <- rep(0, ncol(yj))
} else {
sqrt_imp <- 1 / sqrt(length(items_imp))
sum_y    <- colSums(yj[items_imp, , drop=FALSE]) * sqrt_imp
}
emb_u <- pu[u, ] + sum_y + model$user_emb[u, ]
preds[n] <- as.numeric(mu + bu[u] + bi[i] + qi[i, ] %*% emb_u)
}
return(preds)
}
train_CBASVDpp <- function(train_df, n_users, n_items,
n_clusters=10, k=50,
lr=0.01, lambda=0.02,
n_epochs=20, alpha=0.2) {
# Train ASVD++ base
base <- train_ASVDpp(train_df, n_users, n_items, k, lr, lambda, n_epochs)
epoch_times <- base$epoch_times
build_time  <- base$build_time
# Start Clustering timer
t0_cluster <- proc.time()[3]
mu   <- base$mu; bu <- base$bu; bi <- base$bi
pu   <- base$pu; qi <- base$qi; yj <- base$yj
user_emb  <- base$user_emb; imp_items <- base$imp_items
# Cluster user and item embeddings
uc <- kmeans(user_emb, centers=n_clusters, iter.max=50)$cluster
ic <- kmeans(qi,       centers=n_clusters, iter.max=50)$cluster
uemb_c <- t(sapply(split(seq_len(nrow(user_emb)), uc), function(idx) colMeans(user_emb[idx,,drop=FALSE])))
qi_c   <- t(sapply(split(seq_len(nrow(qi)), ic),       function(idx) colMeans(qi[idx,,drop=FALSE])))
# Cluster bias Rstar
df <- train_df; df$uc <- uc[df$user]; df$ic <- ic[df$item]
Rstar <- with(df, tapply(rating, list(uc,ic), mean)); Rstar[is.na(Rstar)] <- mu
# Get time spent on clustering
cluster_time <- proc.time()[3] - t0_cluster
return(list(mu=mu, bu=bu, bi=bi,
pu=pu, qi=qi, yj=yj,
user_emb=user_emb, imp_items=imp_items,
uemb_c=uemb_c, qi_c=qi_c,
uc=uc, ic=ic,
alpha=alpha,
Rstar=Rstar,
epoch_times = epoch_times,
build_time   = build_time,
cluster_time = cluster_time))
}
predict_CBASVDpp <- function(model, test_df) {
mu <- model$mu; bu <- model$bu; bi <- model$bi
pu <- model$pu; qi <- model$qi; yj <- model$yj
user_emb  <- model$user_emb; imp_items <- model$imp_items
uemb_c <- model$uemb_c; qi_c <- model$qi_c
uc <- model$uc; ic <- model$ic; alpha <- model$alpha; Rstar <- model$Rstar
preds <- numeric(nrow(test_df))
for (n in seq_len(nrow(test_df))) {
u <- test_df$user[n]; i <- test_df$item[n]
# implicit
items_imp <- imp_items[[as.character(u)]]
if (length(items_imp)==0) {
sum_y <- rep(0, ncol(yj))
} else {
sqrt_imp <- 1 / sqrt(length(items_imp))
sum_y    <- colSums(yj[items_imp, , drop=FALSE]) * sqrt_imp
}
# base embedding
emb_base <- pu[u, ] + sum_y + user_emb[u, ]
# cluster mix
p_mix <- (1 - alpha) * emb_base + alpha * uemb_c[uc[u], ]
q_mix <- (1 - alpha) * qi[i, ]    + alpha * qi_c[ic[i], ]
preds[n] <- as.numeric(
mu + bu[u] + bi[i] +
q_mix %*% p_mix +
alpha * (Rstar[uc[u],ic[i]] - mu)
)
}
return(preds)
}
# Baseline SVD++
model_svdpp <- train_SVDpp(train_data, max(train_data$user), max(train_data$item))
preds_svdpp <- predict_SVDpp(model_svdpp, test_data)
# CB-SVD++
model_cb_svdpp <- train_CBSVDpp(train_data, max(train_data$user), max(train_data$item))
preds_cb_svdpp <- predict_CBSVDpp(model_cb_svdpp, test_data)
# ASVD++
model_asvdpp <- train_ASVDpp(train_data, max(train_data$user), max(train_data$item))
preds_asvdpp <- predict_ASVDpp(model_asvdpp, test_data)
# CB- ASVD++
model_cbasvdpp <- train_CBASVDpp(train_data, max(train_data$user), max(train_data$item))
preds_cbasvdpp <- predict_CBASVDpp(model_cbasvdpp, test_data)
# Compute summary table in seconds
timing_summary <- data.frame(
Model = c("SVD++", "CB-SVD++", "ASVD++", "CB-ASVD++"),
EpochTime    = c(
mean(model_svdpp$epoch_times),
mean(model_cb_svdpp$epoch_times),
mean(model_asvdpp$epoch_times),
mean(model_cbasvdpp$epoch_times)
),
BuildTime    = c(NA, NA, model_asvdpp$build_time["elapsed"], model_cbasvdpp$build_time["elapsed"]),
ClusterTime  = c(NA, model_cb_svdpp$cluster_time["elapsed"], NA, model_cbasvdpp$cluster_time["elapsed"])
)
# Compute overall time
timing_summary$OverallTime <- rowSums(
timing_summary[, c("EpochTime", "BuildTime", "ClusterTime")],
na.rm = TRUE
)
# Convert times to milliseconds and append ' ms' suffix
timing_summary_ms <- timing_summary
timing_summary_ms[ , c("EpochTime","BuildTime","ClusterTime", "OverallTime")] <-
timing_summary_ms[ , c("EpochTime","BuildTime","ClusterTime", "OverallTime")] * 1000
for(col in c("EpochTime","BuildTime","ClusterTime", "OverallTime")) {
timing_summary_ms[[col]] <- ifelse(
is.na(timing_summary_ms[[col]]),
NA,
paste0(round(timing_summary_ms[[col]], 0), " ms")
)
}
print(timing_summary_ms)
# Numeric overall times (in seconds) converted to ms
overall_ms <- timing_summary$OverallTime * 1000
# Create barplot
bar_midpoints <- barplot(
overall_ms,
names.arg = timing_summary$Model,
main = "Runtime Comparison",
ylab = "ms per epoche",
col = c("lightskyblue", "dodgerblue", "peachpuff", "darkorange"),
ylim = c(0, max(overall_ms, na.rm = TRUE) * 1.1)
)
# Add values to bars
text(
x = bar_midpoints,
y = overall_ms,
labels = paste0(round(overall_ms, 1), " ms"),
pos = 3,
cex = 0.8
)
# RMSE function
eval_rmse <- function(actual,pred) sqrt(mean((actual-pred)^2,na.rm=TRUE))
# RMSE for baseline SVD++
rmse_svdpp <- eval_rmse(test_data$rating, preds_svdpp)
cat("Baseline SVD++ RMSE:", rmse_svdpp, "\n")
# RMSE for CB-SVD++
rmse_cb_svdpp <- eval_rmse(test_data$rating, preds_cb_svdpp)
cat("CB-SVD++ RMSE:", rmse_cb_svdpp, "\n")
# RMSE for ASVD++
rmse_asvdpp <- eval_rmse(test_data$rating, preds_asvdpp)
cat("ASVD++ RMSE:", rmse_asvdpp, "\n")
# RMSE for CB‑ASVD++
rmse_cbasvdpp    <- eval_rmse(test_data$rating, preds_cbasvdpp)
cat("CB‑ASVD++  RMSE:", rmse_cbasvdpp, "\n")
# MODEL EVALUATION & COMPARISON
# Compare both models visually as well
barplot(
c(SVDpp = rmse_svdpp, CB_SVDpp = rmse_cb_svdpp, ASVDpp = rmse_asvdpp, CB_ASVDpp = rmse_cbasvdpp),
main = "RMSE Comparison",
ylab = "RMSE",
col = c("lightskyblue", "dodgerblue", "peachpuff", "darkorange")
)
svd_grid <- expand.grid(
k      = c(50, 100, 200),
lr     = c(0.005, 0.01),
lambda = c(0.005, 0.01, 0.02)
)
best_svd <- list(rmse = Inf)
for (i in seq_len(nrow(svd_grid))) {
params <- svd_grid[i, ]
cat(sprintf("Training SVD++: k=%d, lr=%.4f, lambda=%.4f\n",
params$k, params$lr, params$lambda))
model_tmp <- train_SVDpp(
train_data,
max(train_data$user), max(train_data$item),
k = params$k,
lr = params$lr,
lambda = params$lambda,
n_epochs = 20
)
preds_tmp <- predict_SVDpp(model_tmp, test_data)
rmse_tmp <- eval_rmse(test_data$rating, preds_tmp)
cat(sprintf(" -> RMSE=%.4f\n", rmse_tmp))
if (rmse_tmp < best_svd$rmse) {
best_svd <- list(model = model_tmp, rmse = rmse_tmp, params = params)
}
}
cat("Best SVD++: ",
sprintf("k=%d, lr=%.4f, lambda=%.4f", best_svd$params$k, best_svd$params$lr, best_svd$params$lambda),
sprintf("RMSE=%.4f\n", best_svd$rmse))
cb_grid <- expand.grid(
n_clusters = c(10, 50, 100),
alpha      = c(0.0, 0.1, 0.15, 0.2, 0.3)
)
best_cb <- list(rmse = Inf)
for (i in seq_len(nrow(cb_grid))) {
params <- cb_grid[i, ]
cat(sprintf("Training CB-SVD++: clusters=%d, alpha=%.2f\n", params$n_clusters, params$alpha))
model_tmp <- train_CBSVDpp(
train_data,
max(train_data$user), max(train_data$item),
n_clusters = params$n_clusters,
k = best_svd$params$k,
lr = best_svd$params$lr,
lambda = best_svd$params$lambda,
n_epochs = 20,
alpha = params$alpha
)
preds_tmp <- predict_CBSVDpp(model_tmp, test_data)
rmse_tmp <- eval_rmse(test_data$rating, preds_tmp)
cat(sprintf(" -> RMSE=%.4f\n", rmse_tmp))
if (rmse_tmp < best_cb$rmse) {
best_cb <- list(model = model_tmp, rmse = rmse_tmp, params = params)
}
}
cat("Best CB-SVD++: ",
sprintf("clusters=%d, alpha=%.2f", best_cb$params$n_clusters, best_cb$params$alpha),
sprintf("RMSE=%.4f\n", best_cb$rmse))
asvd_grid <- expand.grid(
k      = c(50, 100, 200),
lr     = c(0.005, 0.01),
lambda = c(0.005, 0.01, 0.02)
)
best_asvd <- list(rmse=Inf)
for (i in seq_len(nrow(asvd_grid))) {
p <- asvd_grid[i,]
cat(sprintf("ASVD++ train k=%d lr=%.4f λ=%.4f\n", p$k, p$lr, p$lambda))
mtmp <- train_ASVDpp(train_data, max(train_data$user), max(train_data$item),
k=p$k, lr=p$lr, lambda=p$lambda, n_epochs=20)
preds <- predict_ASVDpp(mtmp, test_data)
rmse  <- eval_rmse(test_data$rating, preds)
cat(" -> RMSE=", round(rmse,4), "\n")
if (rmse < best_asvd$rmse) best_asvd <- list(model=mtmp, rmse=rmse, params=p)
}
cat(sprintf(
"Best ASVD++: k=%d, lr=%.4f, lambda=%.4f — RMSE=%.4f\n",
best_asvd$params$k,
best_asvd$params$lr,
best_asvd$params$lambda,
best_asvd$rmse
))
cbasvd_grid <- expand.grid(
n_clusters = c(10, 50, 100),
alpha      = c(0.0, 0.1, 0.15, 0.2, 0.3)
)
best_cbasvd <- list(rmse=Inf)
for (i in seq_len(nrow(cbasvd_grid))) {
p <- cbasvd_grid[i,]
cat(sprintf("CB-ASVD++ train clusters=%d alpha=%.2f\n", p$n_clusters, p$alpha))
mtmp <- train_CBASVDpp(train_data, max(train_data$user), max(train_data$item),
n_clusters=p$n_clusters,
k      = best_asvd$params$k,
lr     = best_asvd$params$lr,
lambda = best_asvd$params$lambda,
n_epochs=20,
alpha  = p$alpha)
preds <- predict_CBASVDpp(mtmp, test_data)
rmse  <- eval_rmse(test_data$rating, preds)
cat(" -> RMSE=", round(rmse,4), "\n")
if (rmse < best_cbasvd$rmse) best_cbasvd <- list(model=mtmp, rmse=rmse, params=p)
}
cat(sprintf(
"Best CB-ASVD++: clusters=%d, alpha=%.2f — RMSE=%.4f\n",
best_cbasvd$params$n_clusters,
best_cbasvd$params$alpha,
best_cbasvd$rmse
))
tuned_comparison_df <- data.frame(
Model    = c("SVD++",      "CB-SVD++",       "ASVD++",        "CB-ASVD++"),
RMSE     = c(best_svd$rmse, best_cb$rmse,    best_asvd$rmse,  best_cbasvd$rmse),
Lambda   = c(best_svd$params$lambda,
best_cb$params$lambda,
best_asvd$params$lambda,
best_cbasvd$params$lambda),
k        = c(best_svd$params$k,
best_cb$params$k,
best_asvd$params$k,
best_cbasvd$params$k),
lr       = c(best_svd$params$lr,
best_cb$params$lr,
best_asvd$params$lr,
best_cbasvd$params$lr),
Alpha    = c(NA,
best_cb$params$alpha,
NA,
best_cbasvd$params$alpha),
Clusters = c(NA,
best_cb$params$n_clusters,
NA,
best_cbasvd$params$n_clusters)
)
tuned_comparison_df
values <- c(SVDpp = best_svd$rmse, CB_SVDpp = best_cb$rmse, ASVDpp = best_asvd$rmse, CB_ASVDpp = best_cbasvd$rmse)
# Create the barplot
bar_midpoints <- barplot(values,
main = "Tuned RMSE Comparison",
ylab = "RMSE",
ylim = c(0, 1.2),
col = c("lightskyblue", "dodgerblue", "peachpuff", "darkorange"))
# Add the values as labels above the bars
text(x = bar_midpoints,
y = values,
labels = round(values, 4),
pos = 3,
cex = 0.8)
# Define a grid of alpha values
a_alpha <- seq(0, 0.6, by = 0.05)
rmses_alpha <- numeric(length(a_alpha))
# Loop over alpha values
for (i in seq_along(a_alpha)) {
alpha_val <- a_alpha[i]
# retrain CB-ASVD++ with new alpha
mod <- train_CBASVDpp(
train_data, max(train_data$user), max(train_data$item),
n_clusters = 10,
k = best_asvd$params$k,
lr = best_asvd$params$lr,
lambda = best_asvd$params$lambda,
n_epochs = 20,
alpha = alpha_val
)
preds <- predict_CBASVDpp(mod, test_data)
rmses_alpha[i] <- eval_rmse(test_data$rating, preds)
}
# Plot RMSE vs alpha
title_str <- "CB-ASVD++: RMSE vs Alpha"
plot(a_alpha, rmses_alpha,
type = "b", pch = 16, lty = 1,
xlab = expression(Alpha~(alpha)),
ylab = "RMSE",
main = title_str,
ylim = c(0.925, 0.96))
# Prepare data
unique_items <- as.integer(levels(as.factor(as.character(ML_df$item))))
info <- data.frame(
item = seq_along(unique_items),
title = orig_titles[unique_items],
stringsAsFactors = FALSE
)
# Cluster ASVD++ item factors
asvd_model <- train_ASVDpp(train_data, max(train_data$user), max(train_data$item))
item_factors <- asvd_model$qi
set.seed(123)
item_clusters <- kmeans(item_factors, centers = 30, iter.max = 50)$cluster
# Merge cluster IDs with titles
clustered_info <- data.frame(
item    = seq_len(nrow(item_factors)),
cluster = item_clusters
) %>% left_join(info, by = "item")
# Display two example clusters: 1 & 2
for (c in 1:2) {
cat(sprintf("Cluster %d:
", c))
clustered_info %>%
filter(cluster == c) %>%
select(title) %>%
head(10) %>%
pull(title) %>%
paste(collapse = ", ") %>%
cat("
")
}
